{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchlibrosa.stft import STFT, ISTFT, magphase\n",
    "import numpy as np\n",
    "\n",
    "stft = STFT(n_fft=1024,\n",
    "            hop_length=320,\n",
    "            win_length=1024,\n",
    "            window='hann',\n",
    "            center=True,\n",
    "            pad_mode='reflect',\n",
    "            freeze_parameters=True)\n",
    "\n",
    "istft = ISTFT(\n",
    "            n_fft=1024,\n",
    "            hop_length=320,\n",
    "            win_length=1024,\n",
    "            window='hann',\n",
    "            center=True,\n",
    "            pad_mode='reflect',\n",
    "            freeze_parameters=True\n",
    "        )\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.0)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "def from_audio_to_spectogram(audios):\n",
    "    magnitudes = []\n",
    "    cosines = []\n",
    "    sines = []\n",
    "\n",
    "    for i in range(audios.shape[1]):\n",
    "\n",
    "        (real,img) = stft(audios[:,i,:])\n",
    "        mag = torch.clamp(real ** 2 + img ** 2, 1e-10, np.inf) ** 0.5\n",
    "        cos = real / mag\n",
    "        sin = img / mag\n",
    "        magnitudes.append(real)\n",
    "        cosines.append(cos)\n",
    "        sines.append(sin)\n",
    "    mags = torch.cat(magnitudes, dim=1)\n",
    "    coss = torch.cat(cosines, dim=1)\n",
    "    sins = torch.cat(sines, dim=1)\n",
    "    \n",
    "    return mags,coss,sins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 513, 501])\n"
     ]
    }
   ],
   "source": [
    "class FilmModule(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(FilmModule, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_size, output_size * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(output_size * 2, output_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,data,embedding_vector):\n",
    "        x = self.linear(embedding_vector)\n",
    "        x = data + x[...,None,None]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "Film1_1 = FilmModule(512,32)\n",
    "\n",
    "random_embedding = torch.rand(1,512)\n",
    "random_value = torch.rand(10,32,513,501)\n",
    "\n",
    "print(Film1_1(random_value,random_embedding).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,input_channels, output_channels, embedding_size, momentum,downsample):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        self.Film1 = FilmModule(embedding_size,input_channels)\n",
    "        self.Film2 = FilmModule(embedding_size,output_channels)\n",
    "\n",
    "         \n",
    "        self.bn1 = nn.BatchNorm2d(input_channels,momentum=momentum)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=(3,3),\n",
    "            stride=(1,1),\n",
    "            dilation=(1,1),\n",
    "            padding=(1,1),\n",
    "            bias=False\n",
    "            )\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(output_channels,momentum=momentum)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=output_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=(3,3),\n",
    "            stride=(1,1),\n",
    "            dilation=(1,1),\n",
    "            padding=(1,1),\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        if input_channels != output_channels:\n",
    "            self.residual_convolution = nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=output_channels,\n",
    "                kernel_size=(1,1),\n",
    "                stride=(1,1),\n",
    "                padding=(0,0),\n",
    "            )\n",
    "            self.has_residual_connection = True\n",
    "        else:\n",
    "            self.has_residual_connection = False\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "\n",
    "        if self.has_residual_connection:\n",
    "            init_layer(self.residual_convolution)\n",
    "    \n",
    "        \n",
    "\n",
    "    def forward(self,input_tensor,embedding_vector):\n",
    "\n",
    "        x = self.bn1(input_tensor)\n",
    "        x = self.Film1(x,embedding_vector)\n",
    "        x = F.leaky_relu(x,negative_slope=0.01)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.Film2(x,embedding_vector)\n",
    "        x = F.leaky_relu(x,negative_slope=0.01)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        if self.has_residual_connection:\n",
    "            y = self.residual_convolution(input_tensor)\n",
    "            x = x + y\n",
    "\n",
    "        x_pool = F.avg_pool2d(x,self.downsample)\n",
    "\n",
    "        return x, x_pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, output_size,embedding_size,momentum,upsample):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        self.conv1 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=output_size,\n",
    "            kernel_size=self.upsample,\n",
    "            stride=self.upsample,\n",
    "            padding=(0,0),\n",
    "            bias=False,\n",
    "            dilation=(1,1)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(input_size,momentum=momentum)\n",
    "        \n",
    "        #self.conv_block2 = ConvBlockRes(\n",
    "        #    out_channels * 2, out_channels, kernel_size, momentum, has_film,\n",
    "        \n",
    "        self.Film1 = FilmModule(embedding_size,input_size)\n",
    "        self.Film2 = FilmModule(embedding_size,output_size*2)\n",
    "        self.Film3 = FilmModule(embedding_size,output_size)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(output_size*2,momentum=momentum)\n",
    "        self.bn3 = nn.BatchNorm2d(output_size,momentum=momentum)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=output_size*2,\n",
    "            out_channels=output_size,\n",
    "            kernel_size=(3,3),\n",
    "            stride=(1,1),\n",
    "            dilation=(1,1),\n",
    "            padding=(1,1),\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=output_size,\n",
    "            out_channels=output_size,\n",
    "            kernel_size=(3,3),\n",
    "            stride=(1,1),\n",
    "            dilation=(1,1),\n",
    "            padding=(1,1),\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.residual_convolution = nn.Conv2d(\n",
    "                in_channels=output_size*2,\n",
    "                out_channels=output_size,\n",
    "                kernel_size=(1,1),\n",
    "                stride=(1,1),\n",
    "                padding=(0,0),\n",
    "            )\n",
    "        self.has_residual_connection = True\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm2d(input_size,momentum=momentum)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_bn(self.bn3)\n",
    "        \n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_layer(self.conv3)\n",
    "\n",
    "        if self.has_residual_connection:\n",
    "            init_layer(self.residual_convolution)\n",
    "\n",
    "    def forward(self,input_tensor,concat_tensor,embedding_vector):\n",
    "        x = self.bn1(input_tensor)\n",
    "        x = self.Film1(x,embedding_vector)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = torch.cat((x,concat_tensor), dim=1)\n",
    "        x_res = x\n",
    "        x = self.bn2(x)\n",
    "        x = self.Film2(x,embedding_vector)\n",
    "        x = F.leaky_relu(x,negative_slope=0.01)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.Film3(x,embedding_vector)\n",
    "        x = F.leaky_relu(x,negative_slope=0.01)\n",
    "        x = self.conv3(x)\n",
    "        if self.has_residual_connection:\n",
    "            y = self.residual_convolution(x_res)\n",
    "\n",
    "            \n",
    "            \n",
    "            x = x + y\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResUnet, self).__init__()\n",
    "\n",
    "        self.input_size = input_size;\n",
    "        self.output_size = output_size;\n",
    "\n",
    "        self.momentum = 0.01 \n",
    "\n",
    "\n",
    "        # instanziare la preconv che è una conv2d\n",
    "\n",
    "        # definire la classe degli encoder block\n",
    "        # definire la classe dei decoder block\n",
    "\n",
    "        self.batch_norm0 = nn.BatchNorm2d(513,momentum=self.momentum)\n",
    "\n",
    "        self.preconvolution = nn.Conv2d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=32,\n",
    "            kernel_size=(1,1),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock1 = EncoderBlock(\n",
    "            input_channels=32,\n",
    "            output_channels=32,\n",
    "            downsample=(2,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock2 = EncoderBlock(\n",
    "            input_channels=32,\n",
    "            output_channels=64,\n",
    "            downsample=(2,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock3 = EncoderBlock(\n",
    "            input_channels=64,\n",
    "            output_channels=128,\n",
    "            downsample=(2,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock4 = EncoderBlock(\n",
    "            input_channels=128,\n",
    "            output_channels=256,\n",
    "            downsample=(2,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock5 = EncoderBlock(\n",
    "            input_channels=256,\n",
    "            output_channels=384,\n",
    "            downsample=(2,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock6 = EncoderBlock(\n",
    "            input_channels=384,\n",
    "            output_channels=384,\n",
    "            downsample=(1,2),\n",
    "            embedding_size=512,\n",
    "            momentum=0.01\n",
    "        )\n",
    "\n",
    "        self.EncoderBlock7 = EncoderBlock(\n",
    "            input_channels=384,\n",
    "            output_channels=384,\n",
    "            downsample=(1,1),\n",
    "            momentum=0.01,\n",
    "            embedding_size=512\n",
    "        )\n",
    "\n",
    "        self.DecoderBlock1 = DecoderBlock(\n",
    "            input_size=384,\n",
    "            output_size= 384,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(1,2)\n",
    "            )\n",
    "        \n",
    "        self.DecoderBlock2 = DecoderBlock(\n",
    "            input_size=384,\n",
    "            output_size= 384,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(2,2)\n",
    "            )\n",
    "        \n",
    "        self.DecoderBlock3 = DecoderBlock(\n",
    "            input_size=384,\n",
    "            output_size= 256,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(2,2)\n",
    "            )\n",
    "        \n",
    "        self.DecoderBlock4 = DecoderBlock(\n",
    "            input_size=256,\n",
    "            output_size= 128,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(2,2)\n",
    "            )\n",
    "        \n",
    "        self.DecoderBlock5 = DecoderBlock(\n",
    "            input_size=128,\n",
    "            output_size= 64,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(2,2)\n",
    "            )\n",
    "        \n",
    "        self.DecoderBlock6 = DecoderBlock(\n",
    "            input_size=64,\n",
    "            output_size= 32,\n",
    "            embedding_size= 512,\n",
    "            momentum=0.01,\n",
    "            upsample=(2,2)\n",
    "            )\n",
    "\n",
    "        \n",
    "        self.after_conv = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=2*3,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        init_bn(self.batch_norm0)\n",
    "        init_layer(self.preconvolution)\n",
    "        init_layer(self.after_conv)\n",
    "\n",
    "    def forward(self,input,embedding_vector):\n",
    "        #x -->mag\n",
    "        #coss--->coss\n",
    "        #sins--->sins\n",
    "        mags,sins,coss = from_audio_to_spectogram(input)\n",
    "        x = mags\n",
    "        x = x.transpose(1,3)\n",
    "        x = self.batch_norm0(x)\n",
    "        x = x.transpose(1,3)\n",
    "        origin_len = x.shape[2]\n",
    "        pad_len = (int(np.ceil(x.shape[2] / 2**5)) * (2**5)- origin_len)\n",
    "        x = F.pad(x, pad=(0, 0, 0, pad_len))\n",
    "        x = x[:,:,:,0:-1]\n",
    "        x = self.preconvolution(x)\n",
    "        \n",
    "        x1, x1_pool = self.EncoderBlock1(x,embedding_vector)\n",
    "        x2, x2_pool = self.EncoderBlock2(x1_pool,embedding_vector)\n",
    "        x3, x3_pool = self.EncoderBlock3(x2_pool,embedding_vector)\n",
    "        x4, x4_pool = self.EncoderBlock4(x3_pool,embedding_vector)\n",
    "        x5, x5_pool = self.EncoderBlock5(x4_pool,embedding_vector)\n",
    "        x6, x6_pool = self.EncoderBlock6(x5_pool,embedding_vector)\n",
    "        x_c,x_c_pool = self.EncoderBlock7(x6_pool,embedding_vector)\n",
    "        x7 = self.DecoderBlock1(x_c,x6,embedding_vector)\n",
    "        x8 = self.DecoderBlock2(x7,x5,embedding_vector)\n",
    "        x9 = self.DecoderBlock3(x8,x4,embedding_vector)\n",
    "        x10 = self.DecoderBlock4(x9,x3,embedding_vector)\n",
    "        x11 = self.DecoderBlock5(x10,x2,embedding_vector)\n",
    "        x12 = self.DecoderBlock6(x11,x1,embedding_vector)\n",
    "        x = self.after_conv(x12)\n",
    "        x = F.pad(x, pad=(0, 1))\n",
    "        x = x[:, :, 0:origin_len, :]\n",
    "        x = x.reshape(\n",
    "            4,\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "            501,\n",
    "            513,\n",
    "        )\n",
    "        mask_mag = torch.sigmoid(x[:, :, :, 0, :, :])\n",
    "        _mask_real = torch.tanh(x[:, :, :, 1, :, :])\n",
    "        _mask_imag = torch.tanh(x[:, :, :, 2, :, :])\n",
    "        _, mask_cos, mask_sin = magphase(_mask_real, _mask_imag)\n",
    "        out_cos = (\n",
    "            coss[:, None, :, :, :] * mask_cos - sins[:, None, :, :, :] * mask_sin\n",
    "        )\n",
    "        out_sin = (\n",
    "            sins[:, None, :, :, :] * mask_cos + coss[:, None, :, :, :] * mask_sin\n",
    "        )\n",
    "        out_mag = F.relu_(mags[:, None, :, :, :] * mask_mag)\n",
    "        out_real = out_mag * out_cos\n",
    "        out_imag = out_mag * out_sin\n",
    "        out_real = out_real.reshape(8,1,501,513)\n",
    "        out_imag = out_imag.reshape(8,1,501,513)\n",
    "        x = istft(out_real, out_imag, 160000)\n",
    "        waveform = x.reshape(4,2,160000)\n",
    "        return waveform\n",
    "        #  eb1(x) = x1,x1_pool\n",
    "        #  eb2(x1) = x2,x2_pool\n",
    "        #  eb3(x2) = x3,x3_pool\n",
    "        #  eb4(x3) = x4,x4_pool\n",
    "        #  eb5(x4) = x5,x5_pool\n",
    "        #  eb6(x5) = x6,x6_pool\n",
    "        #  eb7(x6) = x7\n",
    "        #  db1(x7,x6_pool) = x8\n",
    "        #  db2(x8,x5_pool) = x9\n",
    "        #  db3(x9,x4_pool) = x10\n",
    "        #  db4(x10,x3_pool) = x11\n",
    "        #  db5(x11,x2_pool) = x12\n",
    "        #  db6(x12,x1_pool) = x13\n",
    "        #  x = afterconv(x13) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rete = ResUnet(2,2)\n",
    "random_embedding = torch.rand(1,512)\n",
    "random = torch.rand(4,2,160000)\n",
    "res = rete(random,random_embedding)\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 160000])\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
