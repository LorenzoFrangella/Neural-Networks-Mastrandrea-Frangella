{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libraries required for developing the project"
      ],
      "metadata": {
        "id": "smx0l5hho5NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install laion-clap\n",
        "!pip install transformers==4.30.2\n",
        "!pip install soundfile\n",
        "!pip install librosa\n",
        "!pip install torchlibrosa\n",
        "!pip install ftfy\n",
        "!pip install braceexpand\n",
        "!pip install webdataset\n",
        "!pip install wget\n",
        "!pip install wandb\n",
        "!pip install llvmlite\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install h5py\n",
        "!pip install tqdm\n",
        "!pip install regex\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doc6O-mjOY2O",
        "outputId": "57ab962b-e4b0-4069-9473-1cf1326708c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: laion-clap in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from laion-clap) (1.23.5)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.10.1)\n",
            "Requirement already satisfied: torchlibrosa in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from laion-clap) (6.1.3)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.1.7)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.2.86)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from laion-clap) (3.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.16.1)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.10/dist-packages (from laion-clap) (0.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from laion-clap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from laion-clap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from laion-clap) (1.5.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from laion-clap) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from laion-clap) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from laion-clap) (2023.6.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from laion-clap) (4.30.2)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.10/dist-packages (from laion-clap) (2.5)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->laion-clap) (0.2.12)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->laion-clap) (1.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->laion-clap) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->laion-clap) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->laion-clap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->laion-clap) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (0.20.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->laion-clap) (0.4.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->laion-clap) (3.20.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->laion-clap) (2.21)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->laion-clap) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->laion-clap) (4.0.11)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->laion-clap) (2023.6.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->laion-clap) (4.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->laion-clap) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->laion-clap) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->laion-clap) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->laion-clap) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->laion-clap) (5.0.1)\n",
            "Requirement already satisfied: transformers==4.30.2 in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2023.11.17)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
            "Requirement already satisfied: torchlibrosa in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchlibrosa) (1.23.5)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchlibrosa) (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.8.0->torchlibrosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.8.0->torchlibrosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.8.0->torchlibrosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.8.0->torchlibrosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2023.11.17)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.12)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (0.2.86)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset) (0.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from webdataset) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset) (6.0.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.10/dist-packages (0.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBKZFc14TIfh"
      },
      "outputs": [],
      "source": [
        "import laion_clap\n",
        "import torch\n",
        "from huggingface_hub import hf_hub_download\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "model = laion_clap.CLAP_Module(enable_fusion=False, amodel= 'HTSAT-base')\n",
        "dataset_path = hf_hub_download(repo_id=\"lukewys/laion_clap\", filename=\"music_speech_audioset_epoch_15_esc_89.98.pt\")\n",
        "model.load_ckpt(dataset_path)\n",
        "# quantization\n",
        "def int16_to_float32(x):\n",
        "    return (x / 32767.0).astype(np.float32)\n",
        "\n",
        "\n",
        "def float32_to_int16(x):\n",
        "    x = np.clip(x, a_min=-1., a_max=1.)\n",
        "    return (x * 32767.).astype(np.int16)\n",
        "\n",
        "def get_text_embed( batch):\n",
        "        double_batch = False\n",
        "        if len(batch) == 1:\n",
        "            batch = batch * 2\n",
        "            double_batch = True\n",
        "            text_data = model.tokenizer(batch)\n",
        "            embed = model.model.get_text_embedding(text_data)\n",
        "        if double_batch:\n",
        "            embed = embed[0].unsqueeze(0)\n",
        "\n",
        "        return embed.detach()\n",
        "\n",
        "#text_data = ['pigeons are cooing in the background']\n",
        "#text_input = get_text_embed(text_data)\n",
        "#print(text_input.shape)\n",
        "## Get audio embeddings from audio data\n",
        "#\n",
        "## Get text embedings from texts:\n",
        "#text_data = [\"I love the contrastive learning\",\"I love the pretrain model\"]\n",
        "#text_embed = model.get_text_embedding(text_data)\n",
        "#print(text_embed)\n",
        "#print(text_embed.shape)\n",
        "#audio_file = [\n",
        "#    './audio1.mp3']\n",
        "#audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
        "#print(audio_embed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuova sezione"
      ],
      "metadata": {
        "id": "q0s-3FTsTeAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "lRn8Ivg1OhXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uP76X0i90iPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  pytube import YouTube\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import csv\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "def cut_audio(input_file, output_file, start_time, end_time):\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio = audio.set_frame_rate(32000)\n",
        "    cut_audio = audio[start_time:end_time]\n",
        "    cut_audio.export(output_file, format=\"mp3\")\n",
        "\n",
        "def get_mixture_audio(audio1,audio2):\n",
        "\n",
        "    waveform_s1, sample_rate_s1 = torchaudio.load(audio1)\n",
        "    waveform_s2,sample_rate_s2 = torchaudio.load(audio2)\n",
        "\n",
        "    E1 = torch.square(torch.norm(waveform_s1,p=2))\n",
        "    E2 = torch.square(torch.norm(waveform_s2,p=2))\n",
        "\n",
        "    alpha = torch.sqrt(E1/E2)\n",
        "\n",
        "    x = waveform_s1 + alpha * waveform_s2\n",
        "    return x\n",
        "list_download = os.listdir(\"./download\")\n",
        "def get_audio_clip(video_id, start, end, download=True):\n",
        "\n",
        "    if download:\n",
        "\n",
        "        if f\"{video_id}.mp3\" not in list_download:\n",
        "\n",
        "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "            selected_video = YouTube(video_url)\n",
        "            audio = selected_video.streams.filter(only_audio = True).first()\n",
        "            path_dest = audio.download(\"./download\", filename=f\"{video_id}.mp3\")\n",
        "            cut_audio(path_dest, path_dest, start*1000, end*1000)\n",
        "            print(\"downloaded \"+video_id)\n",
        "\n",
        "        path_dest = f\"./download/{video_id}.mp3\"\n",
        "\n",
        "    else:\n",
        "        print(\"clip \"+video_id + \"already downloaded\")\n",
        "        if f\"{video_id}.mp3\" not in os.listdir(\"./download\"):\n",
        "            return \"\"\n",
        "\n",
        "        else:\n",
        "            path_dest = f\"./download/{video_id}.mp3\"\n",
        "\n",
        "    return path_dest\n",
        "\n",
        "\n",
        "\n",
        "def download_all_dataset():\n",
        "    with open(\"./drive/MyDrive/Neural-Networks/new_balanced.csv\", mode ='r')as file:\n",
        "        csvFile = csv.reader(file)\n",
        "        for lines in csvFile:\n",
        "            video_id = lines[0]\n",
        "            start = lines[1]\n",
        "            end = lines[2]\n",
        "            try:\n",
        "                get_audio_clip(video_id,float(start),float(end))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# get a random row from the file \"new_balanced.csv\"\n",
        "\n",
        "def get_random_pair(file_name):\n",
        "\n",
        "    with open(file_name, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "\n",
        "        random_rows = random.sample(data, 2)\n",
        "\n",
        "        #print(random_rows[0])\n",
        "        #print(random_rows[1])\n",
        "        return random_rows\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_training_element(downloaded=True):\n",
        "    # we get a random pair of audios from the file\n",
        "    if not downloaded:\n",
        "      audios = get_random_pair(\"./drive/MyDrive/Neural-Networks/new_balanced.csv\")\n",
        "    else:\n",
        "      audios = get_random_files(\"/content/Neural-Networks-Mastrandrea-Frangella/download\")\n",
        "\n",
        "    # divide the two audo metadata\n",
        "    audio1_metadata = audios[0]\n",
        "    audio2_metadata = audios[1]\n",
        "\n",
        "    #cast the initial audio time of each track\n",
        "    start1 = float(audio1_metadata[1])\n",
        "    start2 = float(audio2_metadata[1])\n",
        "\n",
        "    #cast the final audio time of each track\n",
        "    end1 = float(audio1_metadata[2])\n",
        "    end2 = float(audio2_metadata[2])\n",
        "\n",
        "    #download the two audio clips, cut them in the defined interval and save\n",
        "\n",
        "    audio1 = get_audio_clip(audio1_metadata[0],start1,end1)\n",
        "    audio2 = get_audio_clip(audio2_metadata[0],start2,end2)\n",
        "\n",
        "    path_clip1 = audio1\n",
        "    path_clip2 = audio2\n",
        "    #load the downloaded files\n",
        "\n",
        "    audio1 = AudioSegment.from_file(audio1)\n",
        "    audio2 = AudioSegment.from_file(audio2)\n",
        "\n",
        "\n",
        "    duration1 = audio1.duration_seconds\n",
        "    duration2 = audio2.duration_seconds\n",
        "\n",
        "    # now we have to sample 5 random seconds from each clip\n",
        "\n",
        "\n",
        "    start_time1 = random.uniform(0,(duration1-5))\n",
        "    start_time2 = random.uniform(0,(duration2-5))\n",
        "\n",
        "    # we cut the two audios in a random sample of 5 second\n",
        "\n",
        "    clipped_audio1 = audio1[start_time1*1000:(start_time1+5)*1000]\n",
        "    clipped_audio2 = audio2[start_time2*1000:(start_time2+5)*1000]\n",
        "\n",
        "    clipped_audio1.export(path_clip1, format=\"mp3\")\n",
        "    clipped_audio2.export(path_clip2, format=\"mp3\")\n",
        "\n",
        "    # we save the two clips and then we combine them\n",
        "\n",
        "    mixed = get_mixture_audio(path_clip1,path_clip2)\n",
        "#\n",
        "    #torchaudio.save(\"./download/mixed.mp3\",mixed,32000)\n",
        "#\n",
        "    #out = torch.stft(mixed,n_fft=1024,hop_length=320,return_complex=True)\n",
        "#\n",
        "    ##return the text to enter into CLAP\n",
        "    #\n",
        "    #\n",
        "#\n",
        "    query = audio1_metadata[-1]\n",
        "#\n",
        "    #print(query)\n",
        "#\n",
        "    #query = query.replace(\"[\",\"\")\n",
        "    #query = query.replace(\"]\",\"\")\n",
        "    #query = query.replace(\",\",\"\")\n",
        "    #query = query.replace(\"'\",\"\")\n",
        "    #\n",
        "    #\n",
        "    #print(query)\n",
        "    #\n",
        "#\n",
        "    #magnitude_spectrogram = torch.abs(out)\n",
        "    #phase_spectrogram = torch.angle(out)\n",
        "\n",
        "    #query = [query]\n",
        "\n",
        "    return (mixed,query)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sure_training_item():\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            element = get_training_element()\n",
        "        except:\n",
        "            continue\n",
        "        break\n",
        "\n",
        "    return element\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "()"
      ],
      "metadata": {
        "id": "Yg-1a7G2TlDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "mtQC8UEl1ZUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/download.zip /content/download\n"
      ],
      "metadata": {
        "id": "u_vnTZOMfr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input(modality):\n",
        "    batch_audio = get_batch()\n",
        "    s1 = random.sample(batch_audio,10)\n",
        "    s2 = random.sample(batch_audio,10)\n",
        "    values = [text_dict[key[:-4]] for key in s1 if key[:-4] in text_dict]\n",
        "    mixed = []\n",
        "    for i in range(10):\n",
        "        audio1 = AudioSegment.from_file(f'./download/{s1[i]}')\n",
        "        audio1 = audio1.set_frame_rate(32000)\n",
        "        audio2 = AudioSegment.from_file(f'./download/{s2[i]}')\n",
        "        audio2 = audio2.set_frame_rate(32000)\n",
        "        duration1 = audio1.duration_seconds\n",
        "        duration2 = audio2.duration_seconds\n",
        "\n",
        "        # now we have to sample 5 random seconds from each clip\n",
        "\n",
        "\n",
        "        start_time1 = random.uniform(0,(duration1-5))\n",
        "        start_time2 = random.uniform(0,(duration2-5))\n",
        "\n",
        "        # we cut the two audios in a random sample of 5 second\n",
        "\n",
        "        clipped_audio1 = audio1[start_time1*1000:(start_time1+5)*1000]\n",
        "        clipped_audio2 = audio2[start_time2*1000:(start_time2+5)*1000]\n",
        "\n",
        "        path_clip1 = \"./tmp/audio1.mp3\"\n",
        "        path_clip2 = \"./tmp/audio2.mp3\"\n",
        "        clipped_audio1.export(path_clip1, format=\"mp3\")\n",
        "        clipped_audio2.export(path_clip2, format=\"mp3\")\n",
        "\n",
        "    # we save the two clips and then we combine them\n",
        "\n",
        "        mixed.append(get_mixture_audio(path_clip1,path_clip2))\n",
        "    if modality == 'text':\n",
        "        return(mixed,values)\n",
        "    else:\n",
        "        if random.random() > 0.5:\n",
        "            return mixed,values\n",
        "        else:\n",
        "            return mixed,[\"./download/\"+elem for elem in s1]\n",
        "\n",
        "\n",
        "\n",
        "def batch():\n",
        "  batch = []\n",
        "  for i in range(10):\n",
        "    batch.append(sure_training_item())\n",
        "  print(batch)\n",
        "\n",
        "\n",
        "def get_random_files(directory, count=20):\n",
        "    files = os.listdir(directory)\n",
        "    random_files = random.sample(files, count)\n",
        "    return random_files\n",
        "\n",
        "def get_batch():\n",
        "    directory_path = './download'\n",
        "    random_files = get_random_files(directory_path, 20)\n",
        "    return random_files"
      ],
      "metadata": {
        "id": "hTIYXEKPNmVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dict = {}\n",
        "with open('./drive/MyDrive/Neural-Networks/new_balanced.csv', mode ='r')as file:\n",
        "        csvFile = csv.reader(file)\n",
        "        for lines in csvFile:\n",
        "            label = lines[4][1:-1]\n",
        "            label = label.replace(\"[\",\"\")\n",
        "            label = label.replace(\"]\",\"\")\n",
        "            label = label.replace(\",\",\"\")\n",
        "            label = label.replace(\"'\",\"\")\n",
        "            text_dict[lines[0]]=label\n"
      ],
      "metadata": {
        "id": "xJf0iZsOPLh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = get_input('text')\n",
        "text_embeddings = model.get_text_embedding(batch[1])\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "BZxNy1fDNnuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pat = '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'\n",
        "!git clone https://{pat}@github.com/LorenzoFrangella/Neural-Networks-Mastrandrea-Frangella"
      ],
      "metadata": {
        "id": "wwH1GwLRy6Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def init_bn(bn):\n",
        "    bn.bias.data.fill_(0.0)\n",
        "    bn.weight.data.fill_(1.0)\n",
        "\n",
        "def init_layer(layer):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    if hasattr(layer, \"bias\"):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "ZdN-INXbzS8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FilmModule(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(FilmModule, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(input_size, output_size * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(output_size * 2, output_size),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,data,embedding_vector):\n",
        "        print(self.input_size)\n",
        "        x = self.linear(embedding_vector)\n",
        "        x = data + x[...,None,None]\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "Film1_1 = FilmModule(512,32)\n",
        "\n",
        "random_embedding = torch.rand(1,512)\n",
        "random_value = torch.rand(32,513,501)\n",
        "\n",
        "print(Film1_1(random_value,random_embedding))\n",
        "\n"
      ],
      "metadata": {
        "id": "kyIl8f17zWkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self,input_channels, output_channels, embedding_size, momentum,downsample):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.downsample = downsample\n",
        "        self.Film1 = FilmModule(embedding_size,input_channels)\n",
        "        self.Film2 = FilmModule(embedding_size,output_channels)\n",
        "\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(input_channels,momentum=momentum)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=input_channels,\n",
        "            out_channels=output_channels,\n",
        "            kernel_size=(3,3),\n",
        "            stride=(1,1),\n",
        "            dilation=(1,1),\n",
        "            padding=(1,1),\n",
        "            bias=False\n",
        "            )\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(output_channels,momentum=momentum)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=output_channels,\n",
        "            out_channels=output_channels,\n",
        "            kernel_size=(3,3),\n",
        "            stride=(1,1),\n",
        "            dilation=(1,1),\n",
        "            padding=(1,1),\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        if input_channels != output_channels:\n",
        "            self.residual_convolution = nn.Conv2d(\n",
        "                in_channels=input_channels,\n",
        "                out_channels=output_channels,\n",
        "                kernel_size=(1,1),\n",
        "                stride=(1,1),\n",
        "                padding=(0,0),\n",
        "            )\n",
        "            self.has_residual_connection = True\n",
        "        else:\n",
        "            self.has_residual_connection = False\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_bn(self.bn1)\n",
        "        init_bn(self.bn2)\n",
        "        init_layer(self.conv1)\n",
        "        init_layer(self.conv2)\n",
        "\n",
        "        if self.has_residual_connection:\n",
        "            init_layer(self.residual_convolution)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,input_tensor,embedding_vector):\n",
        "        x = self.bn1(input_tensor)\n",
        "        x = self.Film1(x,embedding_vector)\n",
        "        x = F.leaky_relu(x,negative_slope=0.01)\n",
        "        x = self.conv1(x)\n",
        "        print(x.shape)\n",
        "        x = self.bn2(x)\n",
        "        x = self.Film2(x,embedding_vector)\n",
        "        x = F.leaky_relu(x,negative_slope=0.01)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        if self.has_residual_connection:\n",
        "            y = self.residual_convolution(input_tensor)\n",
        "            x = x + y\n",
        "\n",
        "        x_pool = F.avg_pool2d(x,self.downsample)\n",
        "\n",
        "        return x, x_pool\n",
        "Encoder1 = EncoderBlock(32,64,512,0.01,(2, 2))\n",
        "input = torch.rand(12,32,513,313)\n",
        "embedding = torch.rand(1,512)\n",
        "res = Encoder1(input,embedding)\n",
        "print(res[0].shape,res[1].shape)"
      ],
      "metadata": {
        "id": "g_MkohQIzX-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size, output_size,embedding_size,momentum,upsample):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.upsample = upsample\n",
        "\n",
        "        self.conv1 = torch.nn.ConvTranspose2d(\n",
        "            in_channels=input_size,\n",
        "            out_channels=output_size,\n",
        "            kernel_size=self.upsample,\n",
        "            stride=self.upsample,\n",
        "            padding=(0,0),\n",
        "            bias=False,\n",
        "            dilation=(1,1)\n",
        "\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(input_size,momentum=momentum)\n",
        "\n",
        "        #self.conv_block2 = ConvBlockRes(\n",
        "        #    out_channels * 2, out_channels, kernel_size, momentum, has_film,\n",
        "\n",
        "        self.Film1 = FilmModule(embedding_size,input_size)\n",
        "        self.Film2 = FilmModule(embedding_size,output_size*2)\n",
        "        self.Film3 = FilmModule(embedding_size,output_size)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(output_size*2,momentum=momentum)\n",
        "        self.bn3 = nn.BatchNorm2d(output_size,momentum=momentum)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=output_size*2,\n",
        "            out_channels=output_size,\n",
        "            kernel_size=(3,3),\n",
        "            stride=(1,1),\n",
        "            dilation=(1,1),\n",
        "            padding=(1,1),\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.conv2d(\n",
        "            in_channels=output_size,\n",
        "            out_channels=output_size,\n",
        "            kernel_size=(3,3),\n",
        "            stride=(1,1),\n",
        "            dilation=(1,1),\n",
        "            padding=(1,1),\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        if input_size != output_size:\n",
        "            self.residual_convolution = nn.Conv2d(\n",
        "                in_channels=input_size,\n",
        "                out_channels=output_size,\n",
        "                kernel_size=(1,1),\n",
        "                stride=(1,1),\n",
        "                padding=(0,0),\n",
        "            )\n",
        "            self.has_residual_connection = True\n",
        "        else:\n",
        "            self.has_residual_connection = False\n",
        "\n",
        "        self.bn4 = nn.BatchNorm2d(input_size,momentum=momentum)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_bn(self.bn1)\n",
        "        init_bn(self.bn2)\n",
        "        init_bn(self.bn3)\n",
        "\n",
        "        init_layer(self.conv1)\n",
        "        init_layer(self.conv2)\n",
        "        init_layer(self.conv3)\n",
        "\n",
        "        if self.has_residual_connection:\n",
        "            init_layer(self.residual_convolution)\n",
        "\n",
        "    def forward(self,input_tensor,concat_tensor,embedding_vector):\n",
        "        x = self.bn1(input_tensor)\n",
        "        x = self.Film1(x,embedding_vector)\n",
        "        x = F.leaky_relu(x)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = torch.cat((x,concat_tensor), dim=1)\n",
        "\n",
        "        x = self.bn2(x)\n",
        "        x = self.Film2(x,embedding_vector)\n",
        "        x = F.leaky_relu(x,negative_slope=0.01)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.Film3(x,embedding_vector)\n",
        "        x = F.leaky_relu(x,negative_slope=0.01)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        if self.has_residual_connection:\n",
        "            y = self.residual_convolution(input_tensor)\n",
        "            x = x + y\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "oUkxcWCNzaAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResUnet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(ResUnet, self).__init__()\n",
        "\n",
        "        self.input_size = input_size;\n",
        "        self.output_size = output_size;\n",
        "\n",
        "        self.momentum = 0.01\n",
        "\n",
        "\n",
        "        # instanziare la preconv che è una conv2d\n",
        "\n",
        "        # definire la classe degli encoder block\n",
        "        # definire la classe dei decoder block\n",
        "\n",
        "        self.batch_norm0 = nn.BatchNorm2d(513,momentum=self.momentum)\n",
        "\n",
        "\n",
        "        self.preconvolution = nn.Conv2d(\n",
        "            input_channels=input_size,\n",
        "            kernel_size=(1,1),\n",
        "            stride=(1,1),\n",
        "            padding=(0,0),\n",
        "            bias=True\n",
        "        )\n",
        "\n",
        "\n",
        "        self.after_conv = nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=output_size * 3,\n",
        "            kernel_size=(1, 1),\n",
        "            stride=(1, 1),\n",
        "            padding=(0, 0),\n",
        "            bias=True,\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,input):\n",
        "\n"
      ],
      "metadata": {
        "id": "W1plhRtlzbVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}